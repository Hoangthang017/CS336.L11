{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "create_tfidf.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNCiRMLkVRAg1HcXMirKIOJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hoangthang017/CS336.L11/blob/master/Do_an_cuoi_ki/create_tfidf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kq5j1lY1cAp",
        "outputId": "67b997d0-602e-43e0-aff0-a2ac30bdde1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# mount gg drive và clone github\r\n",
        "!git clone https://github.com/Hoangthang017/CS336.L11.git\r\n",
        "!pip install underthesea"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'CS336.L11' already exists and is not an empty directory.\n",
            "Requirement already satisfied: underthesea in /usr/local/lib/python3.6/dist-packages (1.3.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from underthesea) (4.41.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from underthesea) (1.0.0)\n",
            "Requirement already satisfied: scikit-learn<0.22,>=0.20 in /usr/local/lib/python3.6/dist-packages (from underthesea) (0.21.3)\n",
            "Requirement already satisfied: torch<=1.5.1,>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from underthesea) (1.5.1)\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.6/dist-packages (from underthesea) (7.1.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from underthesea) (3.2.5)\n",
            "Requirement already satisfied: python-crfsuite>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from underthesea) (0.9.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from underthesea) (2.23.0)\n",
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.6/dist-packages (from underthesea) (1.1.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from underthesea) (3.13)\n",
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.6/dist-packages (from underthesea) (1.2.2)\n",
            "Requirement already satisfied: transformers<=3.5.1,>=3.5.0 in /usr/local/lib/python3.6/dist-packages (from underthesea) (3.5.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn<0.22,>=0.20->underthesea) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn<0.22,>=0.20->underthesea) (1.19.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch<=1.5.1,>=1.1.0->underthesea) (0.16.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk->underthesea) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->underthesea) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->underthesea) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->underthesea) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->underthesea) (1.24.3)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers<=3.5.1,>=3.5.0->underthesea) (3.12.4)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers<=3.5.1,>=3.5.0->underthesea) (0.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers<=3.5.1,>=3.5.0->underthesea) (3.0.12)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers<=3.5.1,>=3.5.0->underthesea) (0.0.43)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers<=3.5.1,>=3.5.0->underthesea) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers<=3.5.1,>=3.5.0->underthesea) (20.8)\n",
            "Requirement already satisfied: tokenizers==0.9.3 in /usr/local/lib/python3.6/dist-packages (from transformers<=3.5.1,>=3.5.0->underthesea) (0.9.3)\n",
            "Requirement already satisfied: sentencepiece==0.1.91 in /usr/local/lib/python3.6/dist-packages (from transformers<=3.5.1,>=3.5.0->underthesea) (0.1.91)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers<=3.5.1,>=3.5.0->underthesea) (50.3.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers<=3.5.1,>=3.5.0->underthesea) (2.4.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96HPArVu140K"
      },
      "source": [
        "# import các thư viện cần thiết\r\n",
        "from glob import glob\r\n",
        "import os\r\n",
        "import sys\r\n",
        "from underthesea import word_tokenize\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import sklearn\r\n",
        "import re\r\n",
        "import string\r\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
        "import pickle"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbH6oYQJ4TWJ"
      },
      "source": [
        "# hàm tiền xử lí văn bản\r\n",
        "def text_preprocess(document):\r\n",
        "  # loại bỏ html nếu có\r\n",
        "  document_test = re.sub(r'@\\w+', '', document)\r\n",
        "\r\n",
        "  # viết thường tất cả \r\n",
        "  document_test = document_test.lower()\r\n",
        "\r\n",
        "  # bỏ dấu câu \r\n",
        "  document_test = re.sub(r'[%s]' % re.escape(string.punctuation), ' ', document_test)\r\n",
        "\r\n",
        "  # thay tern v_league\r\n",
        "  document_test = word_tokenize(document_test,\"text\").replace(\"v league\",\"v_league\")\r\n",
        "  \r\n",
        "  # xóa bỏ các khoảng trắng thừa \r\n",
        "  document_test = re.sub(r'\\s{2,}', ' ', document_test)\r\n",
        "\r\n",
        "  return document_test"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLd2LCsK2PN3"
      },
      "source": [
        "# load dataset\r\n",
        "def load_dataset(files_path):\r\n",
        "  documents_clean = []\r\n",
        "  files_name = []\r\n",
        "  # i = 0\r\n",
        "  for file_path in files_path:\r\n",
        "    # lấy tiêu đề bài viết\r\n",
        "    files_name.append(os.path.basename(file_path).replace(\".txt\",\"\"))\r\n",
        "\r\n",
        "    # lấy nội dung bài viết\r\n",
        "    content = open(file_path,encoding=\"utf8\").read()\r\n",
        "\r\n",
        "    # tiền xử lí dữ liệu\r\n",
        "    document_clean = text_preprocess(content)\r\n",
        "\r\n",
        "    # đếm số văn bản đã được load\r\n",
        "    # i += 1\r\n",
        "    # print(i)\r\n",
        "\r\n",
        "    # thêm văn bản đã load vào\r\n",
        "    documents_clean.append(document_clean)\r\n",
        "  return documents_clean, files_name;"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1YBjlUD8pqo"
      },
      "source": [
        "def create_tfidf(documents_clean):\r\n",
        "  # khởi tạo TfidfVectorizer\r\n",
        "  vectorizer = TfidfVectorizer()\r\n",
        "\r\n",
        "  # fit data vào TfidfVectorizer\r\n",
        "  X = vectorizer.fit_transform(documents_clean)\r\n",
        "\r\n",
        "  # chuyển vị ma trận tfidf\r\n",
        "  X = X.T.toarray()\r\n",
        "\r\n",
        "  # tạo dataframe\r\n",
        "  df_tfidf = pd.DataFrame(X, index=vectorizer.get_feature_names())\r\n",
        "\r\n",
        "  print(vectorizer)\r\n",
        "\r\n",
        "  return df_tfidf, vectorizer"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yY2LTj1EgMO"
      },
      "source": [
        "def get_similar_articles(q, df, files_path, vectorizer):\r\n",
        "  print(\"Câu truy vấn:\", q)\r\n",
        "  # tiền xử lí câu truy vấn\r\n",
        "  q = [text_preprocess(q)]\r\n",
        "  q_vec = vectorizer.transform(q).toarray().reshape(df.shape[0],)\r\n",
        "  # print(q_vec)\r\n",
        "\r\n",
        "  sim = {}\r\n",
        "  # tính toán độ tương đồng\r\n",
        "  for i in range(len(documents_clean)):\r\n",
        "    sim[i] = np.dot(df.loc[:, i].values, q_vec) / np.linalg.norm(df.loc[:, i]) * np.linalg.norm(q_vec)\r\n",
        "  # print('độ dài ', len(sim))\r\n",
        "\r\n",
        "  # sắp xếp độ tương đồng\r\n",
        "  sim_sorted = sorted(sim.items(), key=lambda x: x[1], reverse=True)\r\n",
        "  # print(type(sim_sorted))\r\n",
        "\r\n",
        "  # số lượng bài viết tìm được\r\n",
        "  rank = 10\r\n",
        "  now = 0\r\n",
        "\r\n",
        "  # in kết quả truy vấn được\r\n",
        "  for k, v in sim_sorted:\r\n",
        "    print(\"Độ tương đồng: \", v)\r\n",
        "    print(\"Tiêu đề: \", files_name[k])\r\n",
        "    print(files_path[k])\r\n",
        "    now += 1\r\n",
        "    if (now == rank):\r\n",
        "      break"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_CKWB9-tPRo"
      },
      "source": [
        "# unzip data\r\n",
        "import zipfile\r\n",
        "with zipfile.ZipFile(\"/content/CS336.L11/Dataset_Football/bong_da_v1.zip\", 'r') as zip_ref:\r\n",
        "    zip_ref.extractall(\"/content/CS336.L11/Do_an_cuoi_ki/dataset_football/\")\r\n",
        "# load dataset\r\n",
        "files_path = glob(\"/content/CS336.L11/Do_an_cuoi_ki/dataset_football/Bong Da/*/*.txt\")"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44scMlZrm5cw",
        "outputId": "ecc3913c-310e-4b99-826a-382c3f20482a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# load dataset\r\n",
        "documents_clean , files_name = load_dataset(files_path)\r\n",
        "# tính tfidf\r\n",
        "df_tfidf, vectorizer = create_tfidf(documents_clean)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
            "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
            "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
            "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
            "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
            "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
            "                tokenizer=None, use_idf=True, vocabulary=None)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pp6t1yuR1ncZ"
      },
      "source": [
        "# save file tfidf\r\n",
        "df_tfidf.to_csv('/content/CS336.L11/Do_an_cuoi_ki/dataset_tfidf/tfidf_vector.csv')\r\n",
        "\r\n",
        "# save vectorizer\r\n",
        "with open('/content/CS336.L11/Do_an_cuoi_ki/dataset_tfidf/vectorizer.pk', 'wb') as fin:\r\n",
        "  pickle.dump(vectorizer, fin)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EW-q9tXf4eVW",
        "outputId": "5f2f0839-9919-4648-9a31-1f83484731d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# load data from gg drive \r\n",
        "df_tfidf = pd.read_csv('/content/CS336.L11/Do_an_cuoi_ki/dataset_tfidf/tfidf_vector.csv', index_col=0)\r\n",
        "vec = open('/content/CS336.L11/Do_an_cuoi_ki/dataset_tfidf/vectorizer.pk', 'rb')\r\n",
        "vectorizer = pickle.load(vec)\r\n",
        "vec.close()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
            "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
            "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
            "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
            "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
            "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
            "                tokenizer=None, use_idf=True, vocabulary=None)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENgoaLSIoQqZ",
        "outputId": "5dcab340-291a-4aa0-9e01-832e22bd7e38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# câu truy vấn\r\n",
        "q = 'barcelona'\r\n",
        "# gọi hàm truy vấn\r\n",
        "get_similar_articles(q,df_tfidf,files_path,vectorizer)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             0     1     2     3     4     ...  1193  1194      1195  1196  1197\n",
            "00            0.0   0.0   0.0   0.0   0.0  ...   0.0   0.0  0.000000   0.0   0.0\n",
            "005           0.0   0.0   0.0   0.0   0.0  ...   0.0   0.0  0.000000   0.0   0.0\n",
            "007           0.0   0.0   0.0   0.0   0.0  ...   0.0   0.0  0.000000   0.0   0.0\n",
            "01            0.0   0.0   0.0   0.0   0.0  ...   0.0   0.0  0.000000   0.0   0.0\n",
            "02            0.0   0.0   0.0   0.0   0.0  ...   0.0   0.0  0.000000   0.0   0.0\n",
            "...           ...   ...   ...   ...   ...  ...   ...   ...       ...   ...   ...\n",
            "ứng_cử_viên   0.0   0.0   0.0   0.0   0.0  ...   0.0   0.0  0.070974   0.0   0.0\n",
            "ứng_dụng      0.0   0.0   0.0   0.0   0.0  ...   0.0   0.0  0.000000   0.0   0.0\n",
            "ứng_phó       0.0   0.0   0.0   0.0   0.0  ...   0.0   0.0  0.000000   0.0   0.0\n",
            "ứng_viên      0.0   0.0   0.0   0.0   0.0  ...   0.0   0.0  0.000000   0.0   0.0\n",
            "ứng_xử        0.0   0.0   0.0   0.0   0.0  ...   0.0   0.0  0.000000   0.0   0.0\n",
            "\n",
            "[15210 rows x 1198 columns] TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
            "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
            "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
            "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
            "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
            "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
            "                tokenizer=None, use_idf=True, vocabulary=None)\n",
            "Câu truy vấn: barcelona\n",
            "Độ tương đồng:  0.2173394309208078\n",
            "Tiêu đề:  Guardiola được nhắm đưa về để _cứu_ Barca\n",
            "/content/CS336.L11/Do_an_cuoi_ki/dataset_football/Bong Da/Tây Ban Nha/Guardiola được nhắm đưa về để _cứu_ Barca.txt\n",
            "Độ tương đồng:  0.2028726128874213\n",
            "Tiêu đề:  Với Real, El Clasico  là một... _phiên tòa_\n",
            "/content/CS336.L11/Do_an_cuoi_ki/dataset_football/Bong Da/Tây Ban Nha/Với Real, El Clasico  là một... _phiên tòa_.txt\n",
            "Độ tương đồng:  0.17597054697633088\n",
            "Tiêu đề:  Barca khủng hoảng tài chính do Messi nhiều hơn do Covid-19\n",
            "/content/CS336.L11/Do_an_cuoi_ki/dataset_football/Bong Da/Tây Ban Nha/Barca khủng hoảng tài chính do Messi nhiều hơn do Covid-19.txt\n",
            "Độ tương đồng:  0.15743961046116814\n",
            "Tiêu đề:  Koeman vs Pirlo_ Chỉ là bóng đá thôi mà!\n",
            "/content/CS336.L11/Do_an_cuoi_ki/dataset_football/Bong Da/Champions League/Koeman vs Pirlo_ Chỉ là bóng đá thôi mà!.txt\n",
            "Độ tương đồng:  0.14588722669930643\n",
            "Tiêu đề:  Zidane chưa từng thua tại Nou Camp ở El Clasico\n",
            "/content/CS336.L11/Do_an_cuoi_ki/dataset_football/Bong Da/Tây Ban Nha/Zidane chưa từng thua tại Nou Camp ở El Clasico.txt\n",
            "Độ tương đồng:  0.12673571911561704\n",
            "Tiêu đề:  _Messi đang rất khó chịu tại Barca_\n",
            "/content/CS336.L11/Do_an_cuoi_ki/dataset_football/Bong Da/Tây Ban Nha/_Messi đang rất khó chịu tại Barca_.txt\n",
            "Độ tương đồng:  0.1129058786776406\n",
            "Tiêu đề:  Messi bị ví như _căn bệnh ung thư_ ở Barca\n",
            "/content/CS336.L11/Do_an_cuoi_ki/dataset_football/Bong Da/Tây Ban Nha/Messi bị ví như _căn bệnh ung thư_ ở Barca.txt\n",
            "Độ tương đồng:  0.10090518300674782\n",
            "Tiêu đề:  HLV Tuchel chèo kéo Messi đến PSG sau thất bại ở chung kết Champions League\n",
            "/content/CS336.L11/Do_an_cuoi_ki/dataset_football/Bong Da/Pháp/HLV Tuchel chèo kéo Messi đến PSG sau thất bại ở chung kết Champions League.txt\n",
            "Độ tương đồng:  0.09687091723552999\n",
            "Tiêu đề:  Messi cười khẩy khi bị thầy cũ Setien quở trách\n",
            "/content/CS336.L11/Do_an_cuoi_ki/dataset_football/Bong Da/Tây Ban Nha/Messi cười khẩy khi bị thầy cũ Setien quở trách.txt\n",
            "Độ tương đồng:  0.0936299143734774\n",
            "Tiêu đề:  La Liga có dám phạt Messi vì hành động đá bóng vào trọng tài_\n",
            "/content/CS336.L11/Do_an_cuoi_ki/dataset_football/Bong Da/Tây Ban Nha/La Liga có dám phạt Messi vì hành động đá bóng vào trọng tài_.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUNcaEtJEsjJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}